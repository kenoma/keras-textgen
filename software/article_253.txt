ИИ Google теперь читает по губам лучше, чем человек.
Исследователи из Google DeepMind и Оксфордского университета использовали искусственный интеллект для создания наиболее точного на сегодняшний день программного обеспечения для чтения по губам. Для тренировки нейронной сети учёные использовали тысячи часов записей с BBC, благодаря чему система научилась с вероятностью в 46,8 % определять то, что говорят люди на экране. Результаты могут показаться не такими уж и впечатляющими, особенно если учесть точность транскрибирования искусственным интеллектом аудиозаписей, однако профессионал в чтении по губам смог правильно определить слова в тех же видеороликах лишь в 12,4 % случаев.
Другая группа исследователей из Оксфордского университета ранее в этом месяце отчиталась о похожем проекте. Используя аналогичные технологии, они сумели создать программу LipNet, которая в тестах показала точность в 93,4 %, в то время как точность определения слов человеком составила 52,3 %. Однако программа эта тестировалась только на специально записанном для неё видео, в котором волонтёры зачитывали шаблонные фразы. В свою очередь, программное обеспечение DeepMind, называемое Watch, Listen, Attend, and Spell, транскрибировало естественные, неподготовленные диалоги из политических передач с канала BBC.
Для тренировки нейронной сети использовалось более пяти тысяч часов записей из таких телевизионных шоу, как Newsnight, Question Time и World Today. Ролики включали в себя 118 тысяч различных предложений и около 17,5 тысяч уникальных слов, в то время как в базе видеороликов для тестирования LipNet присутствовало всего 51 уникальное слово.
Исследователи из DeepMind считают, что их новая программа может быть полезна в целом ряде случаев — например, в помощи людям со слабым слухом в понимании диалогов. Она также могла бы быть использована для аннотирования немых фильмов или управления голосовыми помощниками посредством проговаривания слов на камеру.