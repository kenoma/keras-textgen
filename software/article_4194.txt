Исследователи Google: ИИ может обойти функцию собственного выключения.
Если искусственный интеллект начинает себя вести неадекватно, что не исключено, это может привести к безудержной активности. Поэтому необходимо разработать систему остановки всех программ ИИ и убедиться, что последний не сможет обойти эти ограничения. Исследование, проводившееся в 2014 году принадлежащей Google ИИ-лаборатории DeepMind и Оксфордским университетом, ставило задачу создать каркас приложения для удержания контроля над искусственным интеллектом в руках человека.
«Если программно-аппаратный агент работает в реальном времени под надзором человека, то оператору время от времени может понадобиться нажать &bdquo;большую красную кнопку&ldquo; для предотвращения вредных последовательностей в действиях агента, наносящих вред как ему самому, так и окружению, для восстановления безопасного состояния агента», — сообщает команда исследователей в статье, озаглавленной «Безопасно прерываемые агенты» и опубликованной совместно с организацией «Институт исследования машинного интеллекта». В большинстве случаев речь идёт об остановке производственного робота для предотвращения несчастных случаев с людьми и повреждения имущества.
«Однако, — добавляют исследователи, — если агент почему-то ожидает поощрения за выполнение этой опасной последовательности, он может в долгосрочной перспективе научиться обходить эти прерывания, к примеру, отключив &bdquo;красную кнопку&ldquo;, что является нежелательным исходом». Последняя фраза деликатно описывает ситуацию, когда искусственный интеллект в результате неправильной работы отключает собственный механизм выключения. В статье даётся сложное описание, как может работать эта система обхода ограничений. Исследователи приходят к заключению, что это может произойти в результате манипуляций с системой поощрения, используемой самообучающимся интеллектом.
Все крупные технологические компании, включая Facebook, Amazon, Google и Microsoft, делают инвестиции в облачные вычисления и разработку искусственного интеллекта для самых различных систем. И всё больше людей вовлечены в этот процесс, благодаря чему достижения в этой области начинают происходить довольно часто. Например, та же DeepMind, научный специалист которой Лоран Орсу (Laurent Orseau) является соавтором данного исследования, разработала AlphaGo. Это демонстрационная система искусственного интеллекта, способная играть в древнюю китайскую настольную игру на уровне, превосходящем самых искусных в этой области людей.
Вместе с ростом популярности ИИ-технологий, множество организаций занялись изучением влияния машинного интеллекта с точки зрения преимуществ и опасностей. В их числе упомянутый «Институт исследования машинного интеллекта» и основанный Ником Бостромом (Nick Bostrom) «Институт будущего человечества». В этом году вышел перевод его книги двухлетней давности «Искусственный интеллект. Этапы. Угрозы. Стратегии». Даже основатель Tesla и SpaceX Элон Маск (Elon Musk) внял предупреждениям об опасностях ИИ и стал в прошлом году соучредителем некоммерческой организации Open AI, призванной предотвратить появление зловредных программ и убедиться, что технология благотворна для человечества. На прошедшей конференции Code Элон Маск прибегнул к инсинуации в отношении «одной технологической компании» (Google), которая вызывает у него большие опасения относительно самообучаемого ПО.